{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\__init__.py:21: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\__init__.py:21: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import flash\n",
    "import mlflow\n",
    "import torch\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.text import TextClassificationData, TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 22500/22500 [00:00<00:00, 28171.15 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 29759.33 examples/s]\n",
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 30122.41 examples/s]\n",
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3550: FutureWarning: Please pass an instantiated object of the `InputTransform` class. Passing the Class and keyword arguments separately has been deprecated since v0.8.0 and will be removed in v0.9.0.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#download_data(\"https://pl-flash-data.s3.amazonaws.com/imdb.zip\", \"./data/\")\n",
    "datamodule = TextClassificationData.from_csv(\n",
    "    input_field=\"review\",\n",
    "    target_fields=\"sentiment\",\n",
    "    train_file=\"../data/imdb/train.csv\",\n",
    "    val_file=\"../data/imdb/valid.csv\",\n",
    "    test_file=\"../data/imdb/test.csv\",\n",
    "    batch_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'prajjwal1/bert-tiny' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "classifier_model = TextClassifier(backbone=\"prajjwal1/bert-tiny\", num_classes=datamodule.num_classes)\n",
    "trainer = flash.Trainer(max_epochs=3, gpus=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/24 12:24:51 INFO mlflow.tracking.fluent: Experiment with name 'dl_model_chapter03' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"dl_model_chapter03\"\n",
    "mlflow.set_tracking_uri('http://localhost')\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "print(\"experiment_id:\", experiment.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/24 12:25:16 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "Missing logger folder: c:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\lightning_logs\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | train_metrics | ModuleDict         | 0     \n",
      "1 | val_metrics   | ModuleDict         | 0     \n",
      "2 | test_metrics  | ModuleDict         | 0     \n",
      "3 | adapter       | HuggingFaceAdapter | 4.4 M \n",
      "-----------------------------------------------------\n",
      "258       Trainable params\n",
      "4.4 M     Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.545    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8334/8334 [02:54<00:00, 47.80it/s, loss=0.707, v_num=0, train_accuracy_step=1.000, train_cross_entropy_step=0.370, val_accuracy=0.652, val_cross_entropy=0.632, train_accuracy_epoch=0.615, train_cross_entropy_epoch=0.655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 8334/8334 [02:54<00:00, 47.77it/s, loss=0.707, v_num=0, train_accuracy_step=1.000, train_cross_entropy_step=0.370, val_accuracy=0.652, val_cross_entropy=0.632, train_accuracy_epoch=0.615, train_cross_entropy_epoch=0.655]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at c:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\lightning_logs\\version_0\\checkpoints\\epoch=2-step=22500.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at c:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\lightning_logs\\version_0\\checkpoints\\epoch=2-step=22500.ckpt\n",
      "INFO: Loaded model weights from checkpoint at c:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\lightning_logs\\version_0\\checkpoints\\epoch=2-step=22500.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from checkpoint at c:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\lightning_logs\\version_0\\checkpoints\\epoch=2-step=22500.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 834/834 [00:13<00:00, 64.15it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.6528000235557556\n",
      "   test_cross_entropy       0.6299830079078674\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id, run_name=\"chapter03\") as dl_model_tracking_run:\n",
    "    trainer.finetune(classifier_model, datamodule=datamodule, strategy=\"freeze\")\n",
    "    trainer.test(datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: 29bffeb1f278405a86b8a16d41e8ddd5; lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "run_id = dl_model_tracking_run.info.run_id\n",
    "print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
    "    mlflow.get_run(run_id).info.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 31.73it/s] \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "`flash.Task.predict` has been removed. Use `flash.Trainer.predict` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\dl_model_tracking.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Load model as a pytorch model, not as the pyfunc model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mpytorch\u001b[39m.\u001b[39mload_model(logged_model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict({\u001b[39m'\u001b[39;49m\u001b[39mWhat a piece of disappointing news\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\model.py:471\u001b[0m, in \u001b[0;36mTask.predict\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`flash.Task.predict` has been removed. Use `flash.Trainer.predict` instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: `flash.Task.predict` has been removed. Use `flash.Trainer.predict` instead."
     ]
    }
   ],
   "source": [
    "# use the run_id to construct a logged_model URI. An example is shown here:\n",
    "# logged_model = 'runs:/37a3fe9b6faf41d89001eca13ad6ca47/model'\n",
    "logged_model = f'runs:/{run_id}/model'\n",
    "\n",
    "\n",
    "# Load model as a pytorch model, not as the pyfunc model\n",
    "model = mlflow.pytorch.load_model(logged_model)\n",
    "model.predict({'What a piece of disappointing news'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'nlp_dl_model'.\n",
      "2023/11/24 12:37:10 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: nlp_dl_model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: nlp_dl_model\n",
      "Model Version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'nlp_dl_model'.\n"
     ]
    }
   ],
   "source": [
    "# register the model\n",
    "model_registry_version = mlflow.register_model(logged_model, 'nlp_dl_model')\n",
    "print(f'Model Name: {model_registry_version.name}')\n",
    "print(f'Model Version: {model_registry_version.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d47e90b27931bd104cce25434f293e26636b078f01e1bbf5b25a98296951936"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dl_model': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
