{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\__init__.py:21: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\__init__.py:21: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(numpy, tp_name):\n",
      "c:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import flash\n",
    "import mlflow\n",
    "import torch\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.text import TextClassificationData, TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/data/imdb/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Roma\\Documents\\Programming\\Practical-Deep-Learning-at-Scale-with-MLFlow\\chapter03\\dl_model_tracking.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#download_data(\"https://pl-flash-data.s3.amazonaws.com/imdb.zip\", \"./data/\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m datamodule \u001b[39m=\u001b[39m TextClassificationData\u001b[39m.\u001b[39;49mfrom_csv(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     input_field\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     target_fields\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msentiment\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/imdb/train.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     val_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/imdb/valid.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     test_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/imdb/test.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/dl_model_tracking.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\text\\classification\\data.py:220\u001b[0m, in \u001b[0;36mTextClassificationData.from_csv\u001b[1;34m(cls, input_field, target_fields, train_file, val_file, test_file, predict_file, target_formatter, input_cls, transform, transform_kwargs, **data_module_kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the :class:`~flash.text.classification.data.TextClassificationData` from CSV files containing text\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39msnippets and their corresponding targets.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m    >>> os.remove(\"predict_data.tsv\")\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m ds_kw \u001b[39m=\u001b[39m {\n\u001b[0;32m    215\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget_formatter\u001b[39m\u001b[39m\"\u001b[39m: target_formatter,\n\u001b[0;32m    216\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minput_key\u001b[39m\u001b[39m\"\u001b[39m: input_field,\n\u001b[0;32m    217\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtarget_keys\u001b[39m\u001b[39m\"\u001b[39m: target_fields,\n\u001b[0;32m    218\u001b[0m }\n\u001b[1;32m--> 220\u001b[0m train_input \u001b[39m=\u001b[39m input_cls(RunningStage\u001b[39m.\u001b[39mTRAINING, train_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mds_kw)\n\u001b[0;32m    221\u001b[0m ds_kw[\u001b[39m\"\u001b[39m\u001b[39mtarget_formatter\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(train_input, \u001b[39m\"\u001b[39m\u001b[39mtarget_formatter\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    224\u001b[0m     train_input,\n\u001b[0;32m    225\u001b[0m     input_cls(RunningStage\u001b[39m.\u001b[39mVALIDATING, val_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mds_kw),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata_module_kwargs,\n\u001b[0;32m    231\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\data\\io\\input.py:130\u001b[0m, in \u001b[0;36m_wrap_init.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 130\u001b[0m     fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    131\u001b[0m     _validate_input(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\data\\io\\input.py:170\u001b[0m, in \u001b[0;36mInputBase.__init__\u001b[1;34m(self, running_stage, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_STAGES_PREFIX[running_stage]\u001b[39m}\u001b[39;00m\u001b[39m_load_data\u001b[39m\u001b[39m\"\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\data\\io\\input.py:206\u001b[0m, in \u001b[0;36mInputBase.train_load_data\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_load_data\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Sequence, Iterable]:\n\u001b[0;32m    200\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Override the ``train_load_data`` hook with data loading logic that is only required during training.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39m        *args: Any arguments that the input requires.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39m        **kwargs: Any additional keyword arguments that the input requires.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\text\\classification\\input.py:84\u001b[0m, in \u001b[0;36mTextClassificationCSVInput.load_data\u001b[1;34m(self, csv_file, input_key, target_keys, target_formatter)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m@requires\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\n\u001b[0;32m     77\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     target_formatter: Optional[TargetFormatter] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     82\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[0;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mload_data(\n\u001b[1;32m---> 84\u001b[0m         Dataset\u001b[39m.\u001b[39mfrom_pandas(load_data_frame(csv_file)), input_key, target_keys, target_formatter\u001b[39m=\u001b[39mtarget_formatter\n\u001b[0;32m     85\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\data\\utilities\\loading.py:217\u001b[0m, in \u001b[0;36mload_data_frame\u001b[1;34m(file_path, encoding)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load a data frame from a CSV (or similar) file.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    file_path: The file to load.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[39m    encoding: The encoding to use when reading the file.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    216\u001b[0m loaders \u001b[39m=\u001b[39m {extensions: partial(loader, encoding\u001b[39m=\u001b[39mencoding) \u001b[39mfor\u001b[39;00m extensions, loader \u001b[39min\u001b[39;00m _data_frame_loaders\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m load(file_path, loaders)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\flash\\core\\data\\utilities\\loading.py:170\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file_path, loaders)\u001b[0m\n\u001b[0;32m    167\u001b[0m loader \u001b[39m=\u001b[39m _get_loader(file_path, loaders)\n\u001b[0;32m    168\u001b[0m \u001b[39m# escaping file_path to avoid fsspec treating the path as a glob pattern\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m# fsspec ignores `expand=False` in read mode\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[39mwith\u001b[39;00m fsspec\u001b[39m.\u001b[39mopen(escape_file_path(file_path)) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m loader(file)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\fsspec\\core.py:100\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     98\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 100\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfobjects \u001b[39m=\u001b[39m [f]\n\u001b[0;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\fsspec\\spec.py:1307\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1306\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[1;32m-> 1307\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open(\n\u001b[0;32m   1308\u001b[0m         path,\n\u001b[0;32m   1309\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   1310\u001b[0m         block_size\u001b[39m=\u001b[39mblock_size,\n\u001b[0;32m   1311\u001b[0m         autocommit\u001b[39m=\u001b[39mac,\n\u001b[0;32m   1312\u001b[0m         cache_options\u001b[39m=\u001b[39mcache_options,\n\u001b[0;32m   1313\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1314\u001b[0m     )\n\u001b[0;32m   1315\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\fsspec\\implementations\\local.py:180\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 180\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\fsspec\\implementations\\local.py:302\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[1;32mc:\\Users\\Roma\\.virtualenvs\\Practical-Deep-Learning-at-Scale-with-MLFl-NGqyZvc3\\lib\\site-packages\\fsspec\\implementations\\local.py:307\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[0;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[1;32m--> 307\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    308\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[0;32m    309\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:/Users/Roma/Documents/Programming/Practical-Deep-Learning-at-Scale-with-MLFlow/chapter03/data/imdb/train.csv'"
     ]
    }
   ],
   "source": [
    "#download_data(\"https://pl-flash-data.s3.amazonaws.com/imdb.zip\", \"./data/\")\n",
    "datamodule = TextClassificationData.from_csv(\n",
    "    input_field=\"review\",\n",
    "    target_fields=\"sentiment\",\n",
    "    train_file=\"../data/imdb/train.csv\",\n",
    "    val_file=\"../data/imdb/valid.csv\",\n",
    "    test_file=\"../data/imdb/test.csv\",\n",
    "    batch_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'prajjwal1/bert-tiny' provided by Hugging Face/transformers (https://github.com/huggingface/transformers).\n",
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "classifier_model = TextClassifier(backbone=\"prajjwal1/bert-tiny\", num_classes=datamodule.num_classes)\n",
    "trainer = flash.Trainer(max_epochs=3, gpus=torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"dl_model_chapter03\"\n",
    "mlflow.set_tracking_uri('http://localhost')\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "print(\"experiment_id:\", experiment.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/04 17:11:31 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "\n",
      "  | Name          | Type                          | Params\n",
      "----------------------------------------------------------------\n",
      "0 | train_metrics | ModuleDict                    | 0     \n",
      "1 | val_metrics   | ModuleDict                    | 0     \n",
      "2 | model         | BertForSequenceClassification | 4.4 M \n",
      "----------------------------------------------------------------\n",
      "258       Trainable params\n",
      "4.4 M     Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.545    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6250/6250 [02:21<00:00, 44.15it/s, loss=0.618, v_num=0, train_accuracy_step=0.750, train_cross_entropy_step=0.474, val_accuracy=0.635, val_cross_entropy=0.643, train_accuracy_epoch=0.580, train_cross_entropy_epoch=0.756]\n",
      "Testing: 100%|█████████▉| 624/625 [00:09<00:00, 66.44it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.6355999708175659, 'test_cross_entropy': 0.6506440043449402}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 625/625 [00:09<00:00, 66.64it/s]\n"
     ]
    }
   ],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment.experiment_id, run_name=\"chapter03\") as dl_model_tracking_run:\n",
    "    trainer.finetune(classifier_model, datamodule=datamodule, strategy=\"freeze\")\n",
    "    trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: e1af8b8893ca49cfbff1e1077b2b81c5; lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "run_id = dl_model_tracking_run.info.run_id\n",
    "print(\"run_id: {}; lifecycle_stage: {}\".format(run_id,\n",
    "    mlflow.get_run(run_id).info.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the run_id to construct a logged_model URI. An example is shown here:\n",
    "# logged_model = 'runs:/37a3fe9b6faf41d89001eca13ad6ca47/model'\n",
    "logged_model = f'runs:/{run_id}/model'\n",
    "\n",
    "\n",
    "# Load model as a pytorch model, not as the pyfunc model\n",
    "model = mlflow.pytorch.load_model(logged_model)\n",
    "model.predict({'What a piece of disappointing news'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nlp_dl_model' already exists. Creating a new version of this model...\n",
      "2021/12/04 17:21:21 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: nlp_dl_model, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: nlp_dl_model\n",
      "Model Version: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'nlp_dl_model'.\n"
     ]
    }
   ],
   "source": [
    "# register the model\n",
    "model_registry_version = mlflow.register_model(logged_model, 'nlp_dl_model')\n",
    "print(f'Model Name: {model_registry_version.name}')\n",
    "print(f'Model Version: {model_registry_version.version}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d47e90b27931bd104cce25434f293e26636b078f01e1bbf5b25a98296951936"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dl_model': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
